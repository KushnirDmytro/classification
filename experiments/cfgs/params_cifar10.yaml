# general
experiment_name: ""              # prefix of all artifacts ('' means None, create next name)
seed: 42                         # random seed
with_cuda: True                  # CUDA training
path_save: "experiments/logs"    # path to save all artifacts (models, checkpoints, logs)
new_folder: True                 # to handle all experiments in new folders

TRAIN:
  resume: ""
  epochs: 150
  optim: "sgd"                   # support also "adam", "rmsprop"
  lr: 0.01                       # this is for "sgd" optimizer
  momentum: 0.9                  # this is for "sgd" optimizer
  weight_decay: 0.0005           #
  scheduler: "StepLR"            # "StepLR" or ""
  lr_schedule_step: 40           #
  lr_schedule_gamma: 0.1         #

MODEL:
  name: "lenet_in3x32x32_out10"  # could be 'lenet_in3x32x32_out10', 'vgg_bn_pre_in3x32x32_out10', 'vgg_bn_in3x32x32_out10'
  init: "default"                # "default" or  "resnet" or "xavier"
  weights: ""                    #

DATASET:
  name: "cifar10"
  path: "data/cifar10/"
  batch_size: 128                # input batch size for training
  batch_size_val: 256            # input batch size for testing
  download: False
  transforms:
    train: "augment"             # "init", "augment", "augment_simple"
    val: "init"                  # "init"
  tiny: False

LOG:
  iter_interval: 10     # how often (iter) display training details
  visdom: False
  tensorboard: True
  do_checkpoint: True
